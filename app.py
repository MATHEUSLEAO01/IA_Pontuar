import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from openai import OpenAI
from PyPDF2 import PdfReader
import base64

# -----------------------------
# InicializaÃ§Ã£o
# -----------------------------
st.set_page_config(page_title="IA Leitora de Planilhas AvanÃ§ada", layout="wide")
st.title("ğŸ“Š IA Leitora de Planilhas AvanÃ§ada - Pontuar Tech")
st.markdown("1ï¸âƒ£ Envie uma planilha, PDF ou imagem â†’ 2ï¸âƒ£ Informe o tipo â†’ 3ï¸âƒ£ FaÃ§a uma pergunta â†’ 4ï¸âƒ£ Veja a resposta!")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

if "historico" not in st.session_state:
    st.session_state["historico"] = []

# -----------------------------
# FunÃ§Ã£o para extrair conteÃºdo
# -----------------------------
def extrair_conteudo(uploaded_file):
    nome = uploaded_file.name.lower()
    tipo = uploaded_file.type

    # Caso 1: Excel
    if nome.endswith(".xlsx"):
        df = pd.read_excel(uploaded_file)
        return df, None

    # Caso 2: PDF
    elif nome.endswith(".pdf"):
        try:
            reader = PdfReader(uploaded_file)
            texto = ""
            for page in reader.pages:
                texto += page.extract_text() or ""
            return None, texto.strip()
        except Exception:
            # fallback com GPT-4o
            pdf_bytes = uploaded_file.read()
            base64_pdf = base64.b64encode(pdf_bytes).decode("utf-8")
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "user", "content": [
                        {"type": "text", "text": "Extraia todo o texto deste PDF:"},
                        {"type": "image_url", "image_url": f"data:application/pdf;base64,{base64_pdf}"}
                    ]}
                ]
            )
            return None, response.choices[0].message.content

    # Caso 3: Imagem
    elif any(ext in tipo for ext in ["image/png", "image/jpeg", "image/jpg"]):
        img_bytes = uploaded_file.read()
        base64_image = base64.b64encode(img_bytes).decode("utf-8")
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": [
                    {"type": "text", "text": "Extraia todo o texto visÃ­vel desta imagem (OCR):"},
                    {"type": "image_url", "image_url": f"data:image/png;base64,{base64_image}"}
                ]}
            ]
        )
        return None, response.choices[0].message.content

    else:
        return None, None

# -----------------------------
# Upload
# -----------------------------
uploaded_file = st.file_uploader(
    "ğŸ“‚ Envie uma planilha (.xlsx), PDF ou imagem (.png, .jpg)",
    type=["xlsx", "pdf", "png", "jpg", "jpeg"]
)

df = None
texto_extraido = None

if uploaded_file:
    df, texto_extraido = extrair_conteudo(uploaded_file)
    if df is not None:
        st.success("âœ… Planilha Excel carregada!")
    elif texto_extraido:
        st.success("âœ… Texto extraÃ­do com sucesso!")
    else:
        st.error("âŒ NÃ£o foi possÃ­vel processar o arquivo.")
        st.stop()

# -----------------------------
# Entrada do usuÃ¡rio
# -----------------------------
tipo_planilha = st.text_input("ğŸ—‚ Qual o tipo de conteÃºdo? (ex.: vendas, gastos, notas fiscais...)")
pergunta = st.text_input("ğŸ’¬ Sua pergunta:")
tipo_resposta = st.radio("Tipo de resposta:", ["Resumo simples", "Detalhes adicionais"], index=0)

# -----------------------------
# Processamento com GPT
# -----------------------------
if st.button("ğŸ” Perguntar") and (df is not None or texto_extraido) and tipo_planilha:
    try:
        if df is not None:
            resumo = {
                "tipo_planilha": tipo_planilha,
                "colunas": list(df.columns),
                "amostra": df.head(10).to_dict(orient="records"),
            }
            conteudo = f"Resumo da planilha:\n{resumo}\nPergunta: {pergunta}"
        else:
            conteudo = f"Texto detectado:\n{texto_extraido}\nPergunta: {pergunta}"

        prompt_system = (
            "VocÃª Ã© um assistente especialista em anÃ¡lise de planilhas, PDFs e textos financeiros em portuguÃªs. "
            "Analise os dados e responda com clareza e precisÃ£o. "
            "Organize sua resposta em duas partes: 'Resumo simples' e 'Detalhes adicionais'. "
            "Se algo nÃ£o for encontrado, diga 'NÃ£o encontrado'."
        )

        resposta = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompt_system},
                {"role": "user", "content": conteudo}
            ]
        )

        texto_completo = resposta.choices[0].message.content.strip()
        if "Resumo simples:" in texto_completo and "Detalhes adicionais:" in texto_completo:
            resumo_simples = texto_completo.split("Resumo simples:")[1].split("Detalhes adicionais:")[0].strip()
            detalhes = texto_completo.split("Detalhes adicionais:")[1].strip()
        else:
            resumo_simples = texto_completo
            detalhes = texto_completo

        resposta_final = resumo_simples if tipo_resposta == "Resumo simples" else detalhes

        st.subheader("âœ… Resposta:")
        st.write(resposta_final)

        st.session_state["historico"].append({"pergunta": pergunta, "resposta": resposta_final})

    except Exception as e:
        st.error(f"Erro: {e}")

# -----------------------------
# VisualizaÃ§Ãµes
# -----------------------------
if df is not None:
    st.subheader("ğŸ“Š VisualizaÃ§Ãµes bÃ¡sicas")
    numeric_cols = df.select_dtypes(include="number").columns
    if len(numeric_cols) > 0:
        if st.button("ğŸ“ˆ GrÃ¡fico de somas"):
            fig, ax = plt.subplots()
            df[numeric_cols].sum().plot(kind="bar", ax=ax, color="skyblue")
            st.pyplot(fig)
        if st.button("ğŸ“‰ GrÃ¡fico de mÃ©dias"):
            fig, ax = plt.subplots()
            df[numeric_cols].mean().plot(kind="bar", ax=ax, color="lightgreen")
            st.pyplot(fig)
    else:
        st.info("Nenhuma coluna numÃ©rica detectada.")

# -----------------------------
# HistÃ³rico
# -----------------------------
if st.session_state["historico"]:
    st.subheader("ğŸ“œ HistÃ³rico de perguntas recentes")
    for h in reversed(st.session_state["historico"][-5:]):
        st.markdown(f"**Pergunta:** {h['pergunta']}  \n**Resposta:** {h['resposta']}")
