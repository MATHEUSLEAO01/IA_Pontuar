import streamlit as st
import pandas as pd
import pytesseract
from PIL import Image
import pdfplumber
import camelot
from openai import OpenAI
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM

# -----------------------------
# InicializaÃ§Ã£o
# -----------------------------
st.set_page_config(page_title="IA Leitora de Planilhas AvanÃ§ada", layout="wide")
st.title("ğŸ“Š IA Leitora de Planilhas AvanÃ§ada - Pontuar Tech")
st.markdown("1ï¸âƒ£ Envie planilha, PDF ou imagem â†’ 2ï¸âƒ£ Informe o tipo â†’ 3ï¸âƒ£ FaÃ§a uma pergunta â†’ 4ï¸âƒ£ Veja a resposta!")

# OpenAI client
openai_key = st.secrets["general"]["OPENAI_API_KEY"]
client = OpenAI(api_key=openai_key)

# Hugging Face fallback (Flan-T5)
@st.cache_resource
def carregar_modelo_hf():
    tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-large")
    model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-large")
    return pipeline("text2text-generation", model=model, tokenizer=tokenizer)

hf_pipeline = carregar_modelo_hf()

# -----------------------------
# SessÃ£o
# -----------------------------
if "historico" not in st.session_state:
    st.session_state["historico"] = []

# -----------------------------
# Upload
# -----------------------------
uploaded_file = st.file_uploader(
    "ğŸ“‚ Envie planilha (.xlsx), PDF ou imagem (.png, .jpg, .jpeg)",
    type=["xlsx", "pdf", "png", "jpg", "jpeg"]
)

df = None
texto_extraido = None

def extrair_texto_pdf(file):
    texto = ""
    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            texto += page.extract_text() or ""
    return texto

def extrair_tabelas_pdf(file):
    try:
        tables = camelot.read_pdf(file, pages="all", flavor="stream")
        if tables and len(tables) > 0:
            df = tables[0].df
            df.columns = df.iloc[0]
            df = df[1:]
            return df
    except:
        return None
    return None

def extrair_texto_imagem(file):
    imagem = Image.open(file)
    return pytesseract.image_to_string(imagem, lang="por")

if uploaded_file:
    nome = uploaded_file.name.lower()
    try:
        if nome.endswith(".xlsx"):
            df = pd.read_excel(uploaded_file)
            st.success("âœ… Planilha Excel carregada!")
        elif nome.endswith(".pdf"):
            df = extrair_tabelas_pdf(uploaded_file)
            if df is not None:
                st.success("âœ… Tabela detectada no PDF!")
            else:
                texto_extraido = extrair_texto_pdf(uploaded_file)
                st.info("ğŸ“„ Nenhuma tabela detectada â€” texto extraÃ­do para anÃ¡lise.")
        elif nome.endswith((".png", ".jpg", ".jpeg")):
            texto_extraido = extrair_texto_imagem(uploaded_file)
            st.success("âœ… Texto extraÃ­do da imagem!")
    except Exception as e:
        st.error(f"âŒ Erro ao processar arquivo: {e}")
        st.stop()

# -----------------------------
# Tipo de conteÃºdo e pergunta
# -----------------------------
tipo_conteudo = st.text_input("ğŸ—‚ Qual o tipo de conteÃºdo? (ex.: vendas, gastos, estoque...)")
pergunta = st.text_input("ğŸ’¬ Sua pergunta:")

# -----------------------------
# FunÃ§Ã£o para gerar resposta detalhada
# -----------------------------
def gerar_resposta_openai(conteudo):
    try:
        prompt_system = (
            "VocÃª Ã© um assistente especialista em anÃ¡lise de planilhas, PDFs e textos financeiros em portuguÃªs. "
            "ForneÃ§a sempre uma resposta detalhada e precisa, sem resumo simples. "
            "Se nÃ£o encontrar dados suficientes, diga 'NÃ£o encontrado'."
        )
        resposta = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompt_system},
                {"role": "user", "content": conteudo}
            ]
        )
        return resposta.choices[0].message.content.strip()
    except Exception as e:
        return None

def gerar_resposta_hf(texto):
    try:
        saida = hf_pipeline(f"Responda detalhadamente: {texto}", max_length=1024)
        return saida[0]["generated_text"]
    except:
        return None

# -----------------------------
# Processamento
# -----------------------------
if st.button("ğŸ” Perguntar") and (df is not None or texto_extraido) and tipo_conteudo and pergunta:
    conteudo = ""
    if df is not None:
        df_preview = df.head(10).to_dict(orient="records")
        conteudo = f"Tipo: {tipo_conteudo}\nDados:\n{df_preview}\nPergunta: {pergunta}"
    else:
        conteudo = f"Tipo: {tipo_conteudo}\nTexto extraÃ­do:\n{texto_extraido}\nPergunta: {pergunta}"

    # Tenta OpenAI
    resposta = gerar_resposta_openai(conteudo)
    if not resposta:
        # fallback HF gratuito
        resposta = gerar_resposta_hf(conteudo)
    
    if not resposta:
        resposta = "âŒ NÃ£o foi possÃ­vel gerar resposta gratuita."

    st.subheader("âœ… Resposta Detalhada:")
    st.write(resposta)

    # HistÃ³rico
    st.session_state["historico"].append({"pergunta": pergunta, "resposta": resposta})

# -----------------------------
# HistÃ³rico
# -----------------------------
if st.session_state["historico"]:
    st.subheader("ğŸ“œ HistÃ³rico de perguntas recentes")
    for h in reversed(st.session_state["historico"][-5:]):
        st.markdown(f"**Pergunta:** {h['pergunta']}  \n**Resposta:** {h['resposta']}")
